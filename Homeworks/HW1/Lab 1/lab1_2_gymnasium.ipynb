{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqRkYimrQLkw"
   },
   "source": [
    "# Lab 1: Problem 2 (TD-learning with policy improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u19CW-ZQLk0"
   },
   "source": [
    "*OpenAI gym FrozenLake environment*\n",
    "\n",
    "Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend. The surface is described using a grid like the following\n",
    "\n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    "\n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    "\n",
    "    The episode ends when you reach the goal or fall in a hole.\n",
    "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "    \n",
    "    \n",
    "FrozenLake-v1 defines \"solving\" as getting average reward of 0.78 over 100 consecutive trials.\n",
    "\n",
    "More documentation: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from /Users/Akseldkw/Desktop/Columbia/ORCS4529/.env.\n",
      "/Users/Akseldkw/coding/kretsinger/data/nb_log.log\n"
     ]
    }
   ],
   "source": [
    "from kret_studies import *\n",
    "from kret_studies.notebook import *\n",
    "from kret_studies.complex import *\n",
    "\n",
    "logger = get_notebook_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = os.environ.copy()\n",
    "wand_db_dir = env_vars[\"OUTPUT_DIR\"] + \"/wandb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 9009,
     "status": "ok",
     "timestamp": 1727662136000,
     "user": {
      "displayName": "Shipra Agrawal",
      "userId": "12760872725468885671"
     },
     "user_tz": 240
    },
    "id": "RUozkgyaQLk2",
    "outputId": "788fb3d2-1e23-4ea8-df73-3523ca2816a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makseldkw\u001b[0m (\u001b[33makseldkw07\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/Akseldkw/coding/Columbia/ORCS4529-Data/wandb/wandb/run-20251010_123552-wldgkmen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201/runs/wldgkmen' target=\"_blank\">rosy-wildflower-36</a></strong> to <a href='https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201' target=\"_blank\">https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201/runs/wldgkmen' target=\"_blank\">https://wandb.ai/akseldkw07/ORCS4529-Homeworks_HW1_Lab%201/runs/wldgkmen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb set up for logging runs online and moving them to the leaderboard\n",
    "# you will need to create a wandb account when prompted, or if you already have an account login you can simply sign in.\n",
    "# !pip install wandb -qqq\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "run = wandb.init(dir=wand_db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "s82ydg0jQLk4"
   },
   "outputs": [],
   "source": [
    "## DO NOT CHANGE THIS CELL\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import FrozenLakeEnv\n",
    "\n",
    "env = typing.cast(\n",
    "    FrozenLakeEnv, gym.make(\"FrozenLake-v1\", is_slippery=True, success_rate=0.85)\n",
    ")\n",
    "# env.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUkVW_DoQLk4"
   },
   "source": [
    "For proper accounting rewards while you learn, we build a wrapper around env.step() and env.reset(). In an episode, every time you take an action the reward will be appended to the reward of the episode, and when ever the environment is reset (at the end of an epsiode), the episode reward is reset to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-7sXq_2UQLk5"
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "## DO NOT CHANGE THIS CELL\n",
    "# wrapper for accounting rewards\n",
    "rEpisode = 0\n",
    "rList = []\n",
    "fixedWindow = 100\n",
    "movingAverage = 0\n",
    "\n",
    "\n",
    "def reset_decorate(func):\n",
    "    @wraps(func)\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "        global rList\n",
    "        global movingAverage\n",
    "        global rEpisode\n",
    "        global fixedWindow\n",
    "        rList.append(rEpisode)\n",
    "        if len(rList) >= fixedWindow:\n",
    "            movingAverage = np.mean(rList[len(rList) - fixedWindow : len(rList) - 1])\n",
    "        rEpisode = 0\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return func_wrapper\n",
    "\n",
    "\n",
    "env.reset = reset_decorate(env.reset)\n",
    "\n",
    "\n",
    "def step_decorate(func):\n",
    "    @wraps(func)\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "        global rEpisode\n",
    "        # Call the original step function and unpack the result\n",
    "        result = func(*args, **kwargs)\n",
    "        # Handle both 4-tuple and 5-tuple returns for compatibility\n",
    "        if len(result) == 5:\n",
    "            s1, r, d, other, info = result\n",
    "            rEpisode += r\n",
    "            return (s1, r, d, other, info)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected number of return values from env.step\")\n",
    "\n",
    "    return func_wrapper\n",
    "\n",
    "\n",
    "env.step = step_decorate(env.step)\n",
    "\n",
    "\n",
    "def init():\n",
    "    rEpisode = 0\n",
    "    rList = []\n",
    "    movingAverage = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWCPH9ZmQLk6"
   },
   "source": [
    "Below we illustrate the execution of the Open AI gym enviornment using the policy of chosing random action in every state. Every time an action is taken the enviorment returns a tuple containing next state, reward, and the status (whether terminal state is reached or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LF9gIn_IQLk7"
   },
   "outputs": [],
   "source": [
    "### RANDOM SAMPLING EXAMPLE\n",
    "num_episodes = 1000\n",
    "# number of episodes you want to try\n",
    "episode_max_length = 100\n",
    "# you can explicitly end the epsiode before terminal state is reached\n",
    "\n",
    "env.reset()\n",
    "# env.render()\n",
    "# execute in episodes\n",
    "for i in range(num_episodes):\n",
    "\n",
    "    # reset the environment at the beginning of an episode\n",
    "    s = env.reset()\n",
    "    d = False  # not done\n",
    "\n",
    "    for t in range(episode_max_length):\n",
    "\n",
    "        ################ Random action policy ###########################\n",
    "        # play random action\n",
    "        a = env.action_space.sample()\n",
    "        # get new state, reward, done\n",
    "        s, r, d, _, info = env.step(a)\n",
    "        #################################################################\n",
    "\n",
    "        # break if done, reached terminal state\n",
    "        if d == True:\n",
    "            break\n",
    "\n",
    "    # log per-episode reward and moving average over 100 episodes\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"random reward\": rEpisode,\n",
    "            \"random reward moving average\": movingAverage,\n",
    "            \"random episode\": i,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uOnbPBAQLk7"
   },
   "source": [
    "Implement tabular TD-learning with policy improvement (*YOU SHOULD ONLY CHANGE THE CELL BELOW*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_env = typing.cast(FrozenLakeEnv, env.unwrapped)\n",
    "env.observation_space = typing.cast(gym.spaces.Discrete, env.observation_space)\n",
    "env.action_space = typing.cast(gym.spaces.Discrete, env.action_space)\n",
    "\n",
    "\n",
    "def check_valid(state: int, action: int) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the action is valid for the given state.\n",
    "    \"\"\"\n",
    "    state_shift = {0: -1, 1: 4, 2: 1, 3: -4}\n",
    "    next_state = state + state_shift[action]\n",
    "    # Check for invalid moves: out of bounds or wrapping around edges\n",
    "    ncols = grid_env.ncol\n",
    "    nrows = grid_env.nrow\n",
    "\n",
    "    # Compute current row and col\n",
    "    row, col = divmod(state, ncols)\n",
    "\n",
    "    # For left, can't move if col == 0\n",
    "    if action == 0 and col == 0:\n",
    "        return False\n",
    "    # For right, can't move if col == ncols - 1\n",
    "    elif action == 2 and col == ncols - 1:\n",
    "        return False\n",
    "    # For up, can't move if row == 0\n",
    "    elif action == 3 and row == 0:\n",
    "        return False\n",
    "    # For down, can't move if row == nrows - 1\n",
    "    elif action == 1 and row == nrows - 1:\n",
    "        return False\n",
    "    # Out of bounds\n",
    "    elif next_state < 0 or next_state >= env.observation_space.n:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I'm moving this into its own cell so as to avoid resetting Q and n every time I re-run the training cell.\"\"\"\n",
    "\n",
    "# create Q table\n",
    "\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])  # matrix Q[s,a]\n",
    "# create policy\n",
    "pi = np.random.randint(\n",
    "    low=env.action_space.n, size=env.observation_space.n\n",
    ")  # array pi[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; vertical-align:top; margin-right:10px\"><h3>Q</h3><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><div style=\"display:inline-block; vertical-align:top; margin-right:10px\"><h3>pi</h3><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtt(Q, pi, names=[\"Q\", \"pi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxk44HN6QLk8"
   },
   "outputs": [],
   "source": [
    "# initialize episodic structure\n",
    "init()\n",
    "\n",
    "# initialize episodic structure\n",
    "num_episodes = 1000\n",
    "episode_max_length = 100\n",
    "\n",
    "# initialize discount factor, learning rate\n",
    "gamma = 0.95\n",
    "learnRate = 0.80\n",
    "\n",
    "\n",
    "def print_condition(s: int):\n",
    "    return False\n",
    "\n",
    "\n",
    "def learnRate_decay(\n",
    "    episode: int, initial_lr: float = 0.8, decay_rate: float = 0.99, min_lr: float = 0.1\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Decay the learning rate over episodes.\n",
    "    \"\"\"\n",
    "    return max(min_lr, initial_lr * (decay_rate**episode))\n",
    "\n",
    "\n",
    "# SET POLICY ITERATION k=1,2...\n",
    "\n",
    "# RESET Q values\n",
    "\n",
    "# execute in episodes\n",
    "for i in tqdm.tqdm(range(num_episodes)):\n",
    "\n",
    "    # reset the environment at the beginning of an episode\n",
    "    reset_state = env.reset()\n",
    "    s = reset_state[0]\n",
    "    terminated = False  # not done\n",
    "\n",
    "    for t in range(episode_max_length):\n",
    "\n",
    "        ###########SELCT ACTION a for state  using current policy ##################\n",
    "        # example\n",
    "        # a = int(pi[s]) #slightly different for randomized policy\n",
    "        a = (\n",
    "            env.action_space.sample()\n",
    "        )  # currently selecting a random action, change this\n",
    "\n",
    "        if print_condition(s):\n",
    "            print(f\"State {s} {action_values=} {mask=} {a=}\")\n",
    "\n",
    "        # get new state, reward, done\n",
    "        state, reward, terminated, truncated, info = env.step(a)\n",
    "\n",
    "        ##### update Q(s,a) ############\n",
    "        next_max = float(np.max(Q[state, :]))\n",
    "        td = float(reward) + gamma * next_max - Q[s, a]\n",
    "        if print_condition(s):\n",
    "            print(f\"{s=} {a=} {state=} {reward=} {next_max=} {td=}\")\n",
    "        Q[s, a] = Q[s, a] + learnRate_decay(i) * td\n",
    "        n[s, a] += 1\n",
    "\n",
    "        # break if done, reached terminal state\n",
    "        if terminated:\n",
    "            # print(f\"Terminated {i=} {t=}\")\n",
    "            break\n",
    "\n",
    "        if print_condition(s):\n",
    "            print(\"\\n\")\n",
    "\n",
    "        s = state\n",
    "\n",
    "    # log per-episode reward and moving average over 100 episodes\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"training reward\": rEpisode,\n",
    "            \"training reward moving average\": movingAverage,\n",
    "            \"training episode\": i,\n",
    "        }\n",
    "    )\n",
    "\n",
    "wandb.run = typing.cast(wandb.Run, wandb.run)\n",
    "wandb.run.summary[\"number of training episodes\"] = num_episodes\n",
    "\n",
    "#### improve policy pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 2759,
     "status": "ok",
     "timestamp": 1727662144741,
     "user": {
      "displayName": "Shipra Agrawal",
      "userId": "12760872725468885671"
     },
     "user_tz": 240
    },
    "id": "Bs7qXPOHQLk9",
    "outputId": "96aae4c7-5bd5-40d6-e502-75af9e8a619b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/orcs4529/uncategorized/runs/cdxj1fnu?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7dcd7c0f13f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%wandb\n",
    "## DO NOT CHANGE THIS CELL. CHANGING ANY PART OF THIS CELL CAN DISQUALIFY THE SUBMISSION\n",
    "#Evaluation of trained policy\n",
    "init()\n",
    "num_episodes=1000; #number of episodes for evaluation\n",
    "episode_max_length=100\n",
    "movingAverageArray=[]\n",
    "score=0\n",
    "env.reset()\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    d = False #not done\n",
    "    for t in range(episode_max_length):\n",
    "        a = int(pi[s])\n",
    "        s, r, d, _ = env.step(a)\n",
    "        if d == True:\n",
    "            break\n",
    "    #log per-episode reward and moving average over 100 episodes\n",
    "    wandb.log({ \"evaluation reward\" : rEpisode, \"evaluation reward moving average\" : movingAverage, \"evaluation episode\" : i})\n",
    "    movingAverageArray.append(movingAverage)\n",
    "    #score is x if there is a window of 100 consecutive episodes where moving average was at least x\n",
    "    if i>100:\n",
    "        score=max(score,min(movingAverageArray[i-100:i-1]))\n",
    "\n",
    "wandb.run.summary[\"score\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694,
     "referenced_widgets": [
      "ea2f22ed13764eff993d067f8d83b7dc",
      "5e7c939754d14ded828c101e1e921a00",
      "37e5391cdc1f4bd093249ec94f7c0b96",
      "ec2e41f4c0584ee7ada255a165bc704b",
      "5e7829faa9c64b7a9b51d1bd82092bbb",
      "52601c669818413db99cac9c3ead4eda",
      "40a347ac55ee46cea8ebe1d3b252d082",
      "01489fdae31a409d81be38070342d8c1"
     ]
    },
    "executionInfo": {
     "elapsed": 3157,
     "status": "ok",
     "timestamp": 1727662147890,
     "user": {
      "displayName": "Shipra Agrawal",
      "userId": "12760872725468885671"
     },
     "user_tz": 240
    },
    "id": "FYHXbb0JQLk-",
    "outputId": "8070d445-16a5-40d9-964c-64a4fe9fd447"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2f22ed13764eff993d067f8d83b7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.093 MB of 0.093 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>evaluation episode</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>evaluation reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>evaluation reward moving average</td><td>▃▃▃▃▆▆▆▆▆▃▁▁▁▃▃▁▃▆▆▆▆▆▆▁▁▁▁▁▃▃▃▃▃▃▃▃▆██▆</td></tr><tr><td>random episode</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>random reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>random reward moving average</td><td>▁▁▁▁▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▇▇▇▇█▇▇▅▅▁</td></tr><tr><td>training episode</td><td>▁▁▁▁▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>training reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training reward moving average</td><td>▁▁▃▃▃▃▆▃▃▃█▆▆▆▆▁▁▁▁▃▃▃▃▁▃▆▆▆▆█▆▆▆█▆▆▆▆▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>evaluation episode</td><td>999</td></tr><tr><td>evaluation reward</td><td>1</td></tr><tr><td>evaluation reward moving average</td><td>0.0101</td></tr><tr><td>number of training episodes</td><td>1000</td></tr><tr><td>random episode</td><td>999</td></tr><tr><td>random reward</td><td>0</td></tr><tr><td>random reward moving average</td><td>0</td></tr><tr><td>score</td><td>0.0202</td></tr><tr><td>training episode</td><td>999</td></tr><tr><td>training reward</td><td>0</td></tr><tr><td>training reward moving average</td><td>0.0101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-star-1048</strong> at: <a href='https://wandb.ai/orcs4529/uncategorized/runs/cdxj1fnu' target=\"_blank\">https://wandb.ai/orcs4529/uncategorized/runs/cdxj1fnu</a><br/> View project at: <a href='https://wandb.ai/orcs4529/uncategorized' target=\"_blank\">https://wandb.ai/orcs4529/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240930_020853-cdxj1fnu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1rTgTGCQLk-"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01489fdae31a409d81be38070342d8c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37e5391cdc1f4bd093249ec94f7c0b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40a347ac55ee46cea8ebe1d3b252d082",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01489fdae31a409d81be38070342d8c1",
      "value": 1
     }
    },
    "40a347ac55ee46cea8ebe1d3b252d082": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52601c669818413db99cac9c3ead4eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e7829faa9c64b7a9b51d1bd82092bbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e7c939754d14ded828c101e1e921a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e7829faa9c64b7a9b51d1bd82092bbb",
      "placeholder": "​",
      "style": "IPY_MODEL_52601c669818413db99cac9c3ead4eda",
      "value": "0.093 MB of 0.093 MB uploaded\r"
     }
    },
    "ea2f22ed13764eff993d067f8d83b7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e7c939754d14ded828c101e1e921a00",
       "IPY_MODEL_37e5391cdc1f4bd093249ec94f7c0b96"
      ],
      "layout": "IPY_MODEL_ec2e41f4c0584ee7ada255a165bc704b"
     }
    },
    "ec2e41f4c0584ee7ada255a165bc704b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
